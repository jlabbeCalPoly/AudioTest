package com.zybooks.audiotest

import android.app.Activity
import android.content.pm.PackageManager
import android.media.AudioFormat
import android.media.AudioRecord
import android.media.MediaRecorder
import android.os.Process
import android.util.Log
import androidx.compose.runtime.getValue
import androidx.compose.runtime.mutableFloatStateOf
import androidx.compose.runtime.mutableStateOf
import androidx.compose.runtime.setValue
import androidx.compose.ui.graphics.Path
import androidx.core.content.ContextCompat
import androidx.lifecycle.ViewModel
import androidx.lifecycle.viewModelScope
import kotlinx.coroutines.Dispatchers
import kotlinx.coroutines.Job
import kotlinx.coroutines.flow.MutableSharedFlow
import kotlinx.coroutines.flow.MutableStateFlow
import kotlinx.coroutines.flow.StateFlow
import kotlinx.coroutines.flow.asSharedFlow
import kotlinx.coroutines.flow.asStateFlow
import kotlinx.coroutines.launch
import kotlin.math.abs
import kotlin.math.max
import kotlin.math.min

class GraphicalViewModel : ViewModel() {
    private val _data = MutableStateFlow(ShortArray(0))
    val data : StateFlow<ShortArray> = _data.asStateFlow()

    // include ? after Job type since graphicalJob may also be null
    private var recordingJob : Job? = null
    private var processingJob : Job? = null

    // is new audio data being streamed in or not
    var isRecording by mutableStateOf(false)
        private set
    var onStart by mutableStateOf(false)
        private set

    // path generated by the audioData
    var smoothedData: List<Float>? by mutableStateOf(null)
    var width: Float by mutableFloatStateOf(0f)
    var height: Float by mutableFloatStateOf(0f)

    // Y-axis range value for dynamic scaling
    var graphicalAmplitude: Float = 1f

    // Number of divisions for Y-axis labels (excluding zero)
    val yAxisDivisions = 4
    // Stores the values for the Y-axis labels
    var yAxisLabels: List<Float>? by mutableStateOf(null)
        private set

    // Constants
    private var sampleRateInHz = 44100

    fun setGraphSize(width: Float, height: Float) {
        this.width = width
        this.height = height
        // buildPath() will already run if new data is being read in, so
        // no need to recompute the path since it'll already be displayed
        if(!isRecording && onStart) {
            onStart = false
            resizeGraph()
        }
    }

    // This is called each time onStart is invoked in MainActivity.kt
    // Allows the graph to resize properly in the event of a config change
    // and not end up in an infinite loop
    fun setOnStart() {
        onStart = true
    }

    // This function is only to be ran if the user prompts a
    // configuration change while the data acquisition is paused
    fun resizeGraph() {
        if (smoothedData != null) {
            Log.d("Resize", "Resize")
            val currentData = smoothedData?.toList() ?: return

            // Find the max amplitude in the smoothed data
            val dataMax = currentData.maxOrNull() ?: 1f
            val dataMin = currentData.minOrNull() ?: -1f

            val currentMaxAmplitude = max(dataMax, 1f)
            val currentMinAmplitude = min(dataMin, -1f)

            val bound = max(abs(dataMax), abs(dataMin))
            graphicalAmplitude = max(abs(currentMaxAmplitude), abs(currentMinAmplitude))

            var xOffset = 0f
            val lineWidth = width / currentData.size

            // update the YAxis labels, will automatically recompose in GraphicalScreen.kt
            getYAxisLabelValues()

            val path = Path().apply {
                reset()
                moveTo(0f, height / 2) // Start from the middle
                var count = 0
                for (data in currentData) {
                    val offset = data/bound * height/2
                    val yOffset = height/2 + offset
                    xOffset += lineWidth

                    lineTo(xOffset, yOffset)
                    count += 1
                }
                Log.d("Count", "Count in curData is: $count")
            }
        }
    }

    fun startDataAcquisition(activity: Activity, sampleRate: Int) {
        if (ContextCompat.checkSelfPermission(activity, android.Manifest.permission.RECORD_AUDIO) != PackageManager.PERMISSION_GRANTED) {
            return
        }

        if(!isRecording) {
            isRecording = true

            val buffer = AudioRecord.getMinBufferSize(
                sampleRateInHz,
                AudioFormat.CHANNEL_IN_MONO,
                AudioFormat.ENCODING_PCM_16BIT
            )

            val recorder = AudioRecord(
                MediaRecorder.AudioSource.MIC,
                sampleRateInHz,                 // 44100 samples of audio data per second (40,000-48,000 is best practice for high-quality voice recording)
                AudioFormat.CHANNEL_IN_MONO,         // one audio channel, meaning all audio data captured is combined into one signal
                AudioFormat.ENCODING_PCM_16BIT,      // Frequencies are stored as shorts, meaning there are ~65000 possible values that can be returned (This is signed, so negative values are also possible)
                buffer                               // The size of the buffer that can be filled with audio data
            )

   //         val _rawData = MutableStateFlow(ShortArray(0))
   //         val rawData: StateFlow<ShortArray> = _rawData.asStateFlow()

            val _rawData = MutableSharedFlow<ShortArray>()
            val rawData = _rawData.asSharedFlow()

            val samples = (sampleRate * sampleRateInHz) / 1000
            val readBuffer = ShortArray(samples)

            fun handleError(e: Exception) {
                var errorMessage : String = ""
                if (e.message != null) {
                    errorMessage = e.message.toString()
                }
                Log.e("Error", errorMessage)
            }

            fun readData(): Int {
                var readSize : Int = 0
                try {
                    readSize = recorder.read(readBuffer, 0, samples)
                } catch(e: Exception) {
                    handleError(e)
                }
                return readSize
            }

            fun startRecording() {
                recordingJob = viewModelScope.launch(Dispatchers.IO) {
                    Process.setThreadPriority(Process.THREAD_PRIORITY_AUDIO)
                    try {
                        recorder.startRecording()
                        while (isRecording) {
                            val readSize = readData()
                            if (readSize > 0) {
                               // _rawData.value = readBuffer
                                _rawData.emit(readBuffer)
                            }
                        }
                    } catch (e: Exception) {
                        handleError(e)
                    } finally {
                        recorder.stop()
                        recorder.release()
                    }
                }
            }

            fun startProcessing() {
                processingJob = viewModelScope.launch(Dispatchers.Default) {
                    rawData.collect { shortsData ->
                        _data.value = shortsData.copyOf()

                        //val dataMax = shortsData.maxOrNull() ?: 1
                        //val dataMin = shortsData.minOrNull() ?: -1

                        // determine the min/max of the data, used to bound all of the graphical data properly
                        //val dataMaxFloat = dataMax.toFloat()
                        //val dataMinFloat = dataMin.toFloat()

                        //val currentMaxAmplitude = max(dataMaxFloat, 1f)
                        //val currentMinAmplitude = min(dataMinFloat, -1f)

                        //var bound = max(abs(dataMaxFloat), abs(dataMaxFloat))
                        //if (bound == 0f) {
                        //    bound = 1f
                        //}
                        //graphicalAmplitude = max(abs(currentMaxAmplitude), abs(currentMinAmplitude))

                        // Calculate scale to fit in view
                        //val lineWidth = width / floatsData.size
                        //val lineWidth = width / shortsData.size
                        //var xOffset = 0f

                        //val path = Path().apply {
                        //    moveTo(0f, height / 2) // Start from the middle
                        //    for (data in shortsData) {
                        //        val offset = data / bound * height / 2
                        //        val yOffset = height / 2 + offset
                        //        xOffset += lineWidth

                        //        lineTo(xOffset, yOffset)
                        //    }
                        //}
                        //_data.value = path
                    }
                }
            }
            startRecording()
            startProcessing()
        }
    }

    fun cancelGraphical() {
        if(isRecording) {
            recordingJob?.cancel()
            processingJob?.cancel()
            isRecording = false
        }
    }

    // Helper function to get Y-axis label values
    fun getYAxisLabelValues() {
        val max = graphicalAmplitude
        val range = max * 2
        val step = range / yAxisDivisions
        val labels = mutableListOf<Float>()
        for (i in 0..yAxisDivisions) {
            labels.add(max - (step * i))
        }
        yAxisLabels = labels
    }

    // onCleared is called whenever the viewModel is no longer in use
    // prevent memory leaks
    @Override
    override fun onCleared() {
        super.onCleared()
        recordingJob?.cancel()
        processingJob?.cancel()
    }
}